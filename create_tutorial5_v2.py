#!/usr/bin/env python3
"""
Script para crear Tutorial 5 v2: Series Temporales EEG (Versi√≥n Interactiva)
"""

import nbformat as nbf

nb = nbf.v4.new_notebook()

cells = []

# ========== HEADER ==========
cells.append(nbf.v4.new_markdown_cell("""# Tutorial 5: Series Temporales con TDA (Versi√≥n Interactiva)

## An√°lisis Topol√≥gico de Se√±ales EEG Temporales

**Autor:** MARK-126
**Nivel:** Avanzado
**Tiempo estimado:** 150-180 minutos

---

## üéØ Objetivos de Aprendizaje

1. ‚úÖ Dominar embeddings de Takens
2. ‚úÖ Aplicar TDA a se√±ales EEG
3. ‚úÖ Detectar eventos con ventanas deslizantes
4. ‚úÖ Clasificar estados cognitivos
5. ‚úÖ Extraer biomarcadores temporales

---

## ‚ö†Ô∏è Nota sobre Ejercicios

Este notebook contiene **3 ejercicios interactivos** sobre an√°lisis temporal.

---"""))

# ========== TABLE OF CONTENTS ==========
cells.append(nbf.v4.new_markdown_cell("""<a name='toc'></a>
## üìö Tabla de Contenidos

- [1 - Setup e Importaciones](#1)
- [2 - Teorema de Takens](#2)
    - [Ejercicio 1 - takens_embedding](#ex-1)
- [3 - Generaci√≥n de Se√±ales EEG](#3)
- [4 - Ventanas Deslizantes](#4)
    - [Ejercicio 2 - sliding_window_persistence](#ex-2)
- [5 - Clasificaci√≥n de Estados](#5)
    - [Ejercicio 3 - classify_states_with_tda](#ex-3)
- [6 - Resumen](#6)

---"""))

# ========== SECTION 1: SETUP ==========
cells.append(nbf.v4.new_markdown_cell("""<a name='1'></a>
## 1 - Setup e Importaciones

[Volver al √≠ndice](#toc)"""))

cells.append(nbf.v4.new_code_cell("""import numpy as np
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

from ripser import ripser
from persim import plot_diagrams
from scipy import signal
from scipy.fft import fft, fftfreq
from scipy.stats import zscore
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
import pandas as pd

from tda_tests import (
    test_takens_embedding,
    test_sliding_window_persistence,
    test_classify_states_with_tda
)

plt.style.use('seaborn-v0_8-whitegrid')
np.random.seed(42)
print("‚úÖ Setup completado")"""))

# ========== SECTION 2: EXERCISE 1 ==========
cells.append(nbf.v4.new_markdown_cell("""<a name='2'></a>
## 2 - Teorema de Takens y Embeddings

[Volver al √≠ndice](#toc)

### El Problema

Tenemos una **serie temporal 1D**, pero TDA necesita datos multi-dimensionales.

### Soluci√≥n: Teorema de Takens (1981)

Dada serie temporal $x(t)$, reconstruir espacio de estados:

$$\\mathbf{y}(t) = [x(t), x(t+\\tau), x(t+2\\tau), ..., x(t+(d-1)\\tau)]$$

Donde:
- **œÑ (tau):** Delay (retraso temporal)
- **d:** Dimensi√≥n de embedding

<a name='ex-1'></a>
### Ejercicio 1 - takens_embedding

Implementa embedding de Takens con estimaci√≥n autom√°tica de delay.

**Pasos:**
1. Estimar delay √≥ptimo usando autocorrelaci√≥n
2. Crear matriz de embedding
3. Validar dimensionalidad"""))

cells.append(nbf.v4.new_code_cell("""# EJERCICIO 1: Embedding de Takens

def takens_embedding(timeseries, delay=None, dimension=3):
    \"\"\"
    Crea embedding de Takens de una serie temporal.

    Arguments:
    timeseries -- array 1D de la se√±al temporal
    delay -- retraso œÑ (None = estimar autom√°ticamente)
    dimension -- dimensi√≥n del embedding

    Returns:
    embedded -- array (n_points, dimension)
    delay_used -- delay utilizado
    \"\"\"

    # 1. Estimar delay si no se proporciona
    # Calcular autocorrelaci√≥n y encontrar primer m√≠nimo
    # (approx. 8 lines)
    # YOUR CODE STARTS HERE








    # YOUR CODE ENDS HERE

    # 2. Crear matriz de embedding
    # Cada fila: [x(t), x(t+œÑ), x(t+2œÑ), ..., x(t+(d-1)œÑ)]
    # (approx. 7 lines)
    # YOUR CODE STARTS HERE







    # YOUR CODE ENDS HERE

    return embedded, delay_used"""))

cells.append(nbf.v4.new_code_cell("""# Test Ejercicio 1
# Generar se√±al de prueba (sistema de Lorenz)
def lorenz(xyz, t, sigma=10, rho=28, beta=8/3):
    x, y, z = xyz
    return [sigma * (y - x), x * (rho - z) - y, x * y - beta * z]

from scipy.integrate import odeint
t = np.linspace(0, 50, 5000)
xyz = odeint(lorenz, [1.0, 1.0, 1.0], t)
x_signal = xyz[:, 0]

embedded, delay = takens_embedding(x_signal, dimension=3)
print(f"‚úÖ Embedding: {embedded.shape}")
print(f"   Delay: œÑ={delay}")
test_takens_embedding(takens_embedding)"""))

# ========== SECTION 3: EEG GENERATION ==========
cells.append(nbf.v4.new_markdown_cell("""<a name='3'></a>
## 3 - Generaci√≥n de Se√±ales EEG

[Volver al √≠ndice](#toc)

Generamos se√±ales EEG sint√©ticas con diferentes estados:
- **Normal:** Alpha (8-13 Hz) + Beta (13-30 Hz)
- **Seizure:** Spike-wave a 3 Hz
- **Sleep:** Delta (0.5-4 Hz)"""))

cells.append(nbf.v4.new_code_cell("""def generate_eeg_signal(duration=10, fs=250, state='normal'):
    \"\"\"Genera se√±al EEG sint√©tica.\"\"\"
    n_samples = int(duration * fs)
    t = np.linspace(0, duration, n_samples)

    if state == 'normal':
        alpha = 0.5 * np.sin(2 * np.pi * 10 * t)
        beta = 0.3 * np.sin(2 * np.pi * 20 * t)
        noise = 0.2 * np.random.randn(n_samples)
        eeg = alpha + beta + noise

    elif state == 'seizure':
        spike_wave = 2.0 * np.sin(2 * np.pi * 3 * t)
        harmonics = 0.5 * np.sin(2 * np.pi * 6 * t)
        noise = 0.1 * np.random.randn(n_samples)
        eeg = spike_wave + harmonics + noise

    elif state == 'sleep':
        delta = 1.5 * np.sin(2 * np.pi * 2 * t)
        theta = 0.3 * np.sin(2 * np.pi * 6 * t)
        noise = 0.15 * np.random.randn(n_samples)
        eeg = delta + theta + noise

    return t, eeg

# Generar se√±ales
t_normal, eeg_normal = generate_eeg_signal(duration=10, state='normal')
t_seizure, eeg_seizure = generate_eeg_signal(duration=10, state='seizure')
t_sleep, eeg_sleep = generate_eeg_signal(duration=10, state='sleep')

print(f"‚úÖ Se√±ales generadas: {len(eeg_normal)} muestras cada una")"""))

# ========== SECTION 4: EXERCISE 2 ==========
cells.append(nbf.v4.new_markdown_cell("""<a name='4'></a>
## 4 - An√°lisis con Ventanas Deslizantes

[Volver al √≠ndice](#toc)

<a name='ex-2'></a>
### Ejercicio 2 - sliding_window_persistence

Detecta eventos usando ventanas deslizantes y persistencia.

**Estrategia:**
1. Dividir se√±al en ventanas solapadas
2. Calcular embedding de Takens en cada ventana
3. Extraer persistencia H‚ÇÅ
4. Detectar cambios topol√≥gicos"""))

cells.append(nbf.v4.new_code_cell("""# EJERCICIO 2: Ventanas Deslizantes

def sliding_window_persistence(signal, window_size=500, stride=100, fs=250):
    \"\"\"
    Analiza se√±al con ventanas deslizantes y TDA.

    Arguments:
    signal -- se√±al temporal 1D
    window_size -- tama√±o de ventana (muestras)
    stride -- paso de desplazamiento
    fs -- frecuencia de muestreo

    Returns:
    time_points -- puntos temporales centrales
    n_cycles_over_time -- n√∫mero de ciclos H‚ÇÅ en cada ventana
    max_persistence_over_time -- persistencia m√°xima en cada ventana
    \"\"\"
    n_samples = len(signal)
    time_points = []
    n_cycles_over_time = []
    max_persistence_over_time = []

    # 1. Iterar sobre ventanas deslizantes
    # (approx. 2 lines)
    # YOUR CODE STARTS HERE


    # YOUR CODE ENDS HERE

        # 2. Extraer ventana y normalizar
        # (approx. 3 lines)
        # YOUR CODE STARTS HERE



        # YOUR CODE ENDS HERE

        # 3. Crear embedding de Takens
        # (approx. 2 lines)
        # YOUR CODE STARTS HERE


        # YOUR CODE ENDS HERE

        # 4. Calcular persistencia H‚ÇÅ
        # (approx. 5 lines)
        # YOUR CODE STARTS HERE





        # YOUR CODE ENDS HERE

        # 5. Guardar resultados
        # (approx. 3 lines)
        # YOUR CODE STARTS HERE



        # YOUR CODE ENDS HERE

    return np.array(time_points), np.array(n_cycles_over_time), np.array(max_persistence_over_time)"""))

cells.append(nbf.v4.new_code_cell("""# Test Ejercicio 2
time_pts, n_cycles, max_pers = sliding_window_persistence(eeg_normal,
                                                          window_size=500,
                                                          stride=100)
print(f"‚úÖ Ventanas analizadas: {len(time_pts)}")
print(f"   Ciclos promedio: {np.mean(n_cycles):.1f}")
test_sliding_window_persistence(sliding_window_persistence)"""))

# ========== SECTION 5: EXERCISE 3 ==========
cells.append(nbf.v4.new_markdown_cell("""<a name='5'></a>
## 5 - Clasificaci√≥n de Estados Cerebrales

[Volver al √≠ndice](#toc)

<a name='ex-3'></a>
### Ejercicio 3 - classify_states_with_tda

Clasifica estados cerebrales usando caracter√≠sticas topol√≥gicas.

**Features a extraer:**
- TDA: n_cycles, max_persistence, mean_persistence
- Espectrales: potencia en bandas (delta, alpha, beta)
- Temporales: media, std"""))

cells.append(nbf.v4.new_code_cell("""# EJERCICIO 3: Clasificaci√≥n

def classify_states_with_tda(signals_dict, test_size=0.3):
    \"\"\"
    Clasifica estados cerebrales usando TDA + features espectrales.

    Arguments:
    signals_dict -- diccionario {state_name: list_of_signals}
    test_size -- proporci√≥n de test

    Returns:
    clf -- clasificador entrenado
    accuracy -- precisi√≥n en test
    report -- reporte de clasificaci√≥n
    \"\"\"
    X_data = []
    y_data = []
    state_names = list(signals_dict.keys())

    # 1. Extraer features de cada se√±al
    # (approx. 12 lines para embedding + persistencia + espectrales)
    # YOUR CODE STARTS HERE












    # YOUR CODE ENDS HERE

    # 2. Convertir a arrays
    # (approx. 2 lines)
    # YOUR CODE STARTS HERE


    # YOUR CODE ENDS HERE

    # 3. Dividir train/test
    # (approx. 2 lines)
    # YOUR CODE STARTS HERE


    # YOUR CODE ENDS HERE

    # 4. Entrenar Random Forest
    # (approx. 2 lines)
    # YOUR CODE STARTS HERE


    # YOUR CODE ENDS HERE

    # 5. Evaluar
    # (approx. 3 lines)
    # YOUR CODE STARTS HERE



    # YOUR CODE ENDS HERE

    return clf, accuracy, report"""))

cells.append(nbf.v4.new_code_cell("""# Generar dataset
signals_dataset = {
    'normal': [generate_eeg_signal(duration=5, state='normal')[1] for _ in range(50)],
    'seizure': [generate_eeg_signal(duration=5, state='seizure')[1] for _ in range(50)],
    'sleep': [generate_eeg_signal(duration=5, state='sleep')[1] for _ in range(50)]
}

# Test Ejercicio 3
clf, acc, report = classify_states_with_tda(signals_dataset)
print(f"‚úÖ Clasificador entrenado")
print(f"   Precisi√≥n: {acc:.1%}")
print(f"\\n{report}")
test_classify_states_with_tda(classify_states_with_tda)"""))

# ========== SECTION 6: SUMMARY ==========
cells.append(nbf.v4.new_markdown_cell("""<a name='6'></a>
## 6 - Resumen

[Volver al √≠ndice](#toc)

<div style="background-color:#e3f2fd; padding:15px; border-left:5px solid #2196f3;">

**üí° Lo que aprendimos:**

- **Teorema de Takens** reconstruye din√°mica desde se√±al 1D
- **Embeddings** transforman series temporales en nubes de puntos
- **Ventanas deslizantes** detectan eventos temporales
- **TDA + ML** clasifica estados cerebrales con alta precisi√≥n
- **Aplicaciones cl√≠nicas** incluyen epilepsia, sue√±o, anestesia

</div>

---

### üß† Aplicaciones Cl√≠nicas

**Epilepsia:** Detecci√≥n temprana de crisis (cambios topol√≥gicos)
**Sue√±o:** Clasificaci√≥n autom√°tica de etapas
**Anestesia:** Monitoreo de profundidad
**Coma:** Evaluaci√≥n de nivel de consciencia

---

## üéâ ¬°Excelente trabajo!

Has completado el an√°lisis topol√≥gico de series temporales.

---

**Autor:** MARK-126
**Licencia:** MIT"""))

# ========== CREATE NOTEBOOK ==========
nb['cells'] = cells

with open('notebooks/05_Series_Temporales_EEG_v2.ipynb', 'w') as f:
    nbf.write(nb, f)

print("‚úÖ Tutorial 5 v2 creado: notebooks/05_Series_Temporales_EEG_v2.ipynb")
