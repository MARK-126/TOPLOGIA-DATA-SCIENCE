#!/usr/bin/env python3
"""
Script para expandir Tutorial 1 v2 con ejercicios adicionales
"""

import nbformat as nbf

# Leer notebook existente
with open('notebooks/01_Introduccion_TDA_v2.ipynb', 'r') as f:
    nb = nbf.read(f, as_version=4)

# Encontrar posici√≥n para insertar nuevos ejercicios (antes del resumen final)
# Los nuevos ejercicios ir√°n entre el Ejercicio 4 y el Resumen
insert_idx = len(nb.cells) - 1  # Antes de la √∫ltima celda (resumen)

new_cells = []

# ========== EJERCICIO 5: Comparar caracter√≠sticas topol√≥gicas ==========
new_cells.append(nbf.v4.new_markdown_cell("""### Ejercicio 5 - compare_topological_features

Compara caracter√≠sticas topol√≥gicas entre dos datasets.

**Objetivo:** Cuantificar similitud topol√≥gica entre estados cerebrales

**Instrucciones:**
1. Calcular homolog√≠a persistente para ambos datasets
2. Extraer caracter√≠sticas: max persistence, total persistence, n_cycles
3. Calcular distancia euclidiana entre vectores de caracter√≠sticas
4. Retornar diccionario con caracter√≠sticas y distancia"""))

new_cells.append(nbf.v4.new_code_cell("""# EJERCICIO 5: Comparar Caracter√≠sticas Topol√≥gicas

def compare_topological_features(data1, data2, max_dim=2):
    \"\"\"
    Compara caracter√≠sticas topol√≥gicas entre dos datasets.

    Arguments:
    data1 -- primer dataset (n_samples1, n_features)
    data2 -- segundo dataset (n_samples2, n_features)
    max_dim -- dimensi√≥n m√°xima para homolog√≠a

    Returns:
    features1 -- diccionario con caracter√≠sticas del dataset 1
    features2 -- diccionario con caracter√≠sticas del dataset 2
    distance -- distancia euclidiana entre vectores de caracter√≠sticas
    \"\"\"

    # 1. Calcular homolog√≠a para data1
    # (approx. 2 lines)
    # YOUR CODE STARTS HERE


    # YOUR CODE ENDS HERE

    # 2. Calcular homolog√≠a para data2
    # (approx. 2 lines)
    # YOUR CODE STARTS HERE


    # YOUR CODE ENDS HERE

    # 3. Extraer caracter√≠sticas de H1 (ciclos) para data1
    # (approx. 8 lines)
    # Caracter√≠sticas: n_cycles, max_persistence, total_persistence
    # YOUR CODE STARTS HERE








    # YOUR CODE ENDS HERE

    # 4. Extraer caracter√≠sticas de H1 para data2
    # (approx. 8 lines)
    # YOUR CODE STARTS HERE








    # YOUR CODE ENDS HERE

    # 5. Calcular distancia euclidiana entre vectores de caracter√≠sticas
    # (approx. 4 lines)
    # Crear vectores [n_cycles, max_persistence, total_persistence]
    # YOUR CODE STARTS HERE




    # YOUR CODE ENDS HERE

    return features1, features2, distance"""))

new_cells.append(nbf.v4.new_code_cell("""# Test del Ejercicio 5
f1, f2, dist = compare_topological_features(resting_state, active_state, max_dim=2)

print("Caracter√≠sticas topol√≥gicas:")
print(f"\\nEstado de reposo:")
print(f"  ‚Ä¢ Ciclos (H‚ÇÅ): {f1['n_cycles']}")
print(f"  ‚Ä¢ Max persistencia: {f1['max_persistence']:.3f}")
print(f"  ‚Ä¢ Persistencia total: {f1['total_persistence']:.3f}")

print(f"\\nEstado activo:")
print(f"  ‚Ä¢ Ciclos (H‚ÇÅ): {f2['n_cycles']}")
print(f"  ‚Ä¢ Max persistencia: {f2['max_persistence']:.3f}")
print(f"  ‚Ä¢ Persistencia total: {f2['total_persistence']:.3f}")

print(f"\\nüìä Distancia topol√≥gica: {dist:.3f}")
print("(Mayor distancia ‚Üí estados m√°s diferentes topol√≥gicamente)")

# Test autom√°tico
from tda_tests import test_compare_topological_features
test_compare_topological_features(compare_topological_features)"""))

new_cells.append(nbf.v4.new_markdown_cell("""<div style="background-color:#e3f2fd; padding:15px; border-left:5px solid #2196f3; margin: 20px 0;">

**üí° Interpretaci√≥n:**

- **Distancia alta** ‚Üí Estados cerebrales topol√≥gicamente diferentes
- **Distancia baja** ‚Üí Estados similares (mismo nivel de organizaci√≥n)
- √ötil para **clasificaci√≥n de estados** cognitivos
- Robusto al ruido en comparaci√≥n con m√©tricas tradicionales

</div>

---"""))

# ========== EJERCICIO 6: Filtrar por persistencia ==========
new_cells.append(nbf.v4.new_markdown_cell("""### Ejercicio 6 - filter_by_persistence

Filtra caracter√≠sticas topol√≥gicas por su persistencia.

**Objetivo:** Eliminar ruido y mantener solo caracter√≠sticas significativas

**Concepto:** La persistencia (death - birth) mide cu√°n "robusta" es una caracter√≠stica.
Caracter√≠sticas con baja persistencia suelen ser ruido.

**Instrucciones:**
1. Calcular persistencia para cada caracter√≠stica
2. Filtrar caracter√≠sticas con persistencia >= threshold
3. Retornar diagrama filtrado"""))

new_cells.append(nbf.v4.new_code_cell("""# EJERCICIO 6: Filtrar por Persistencia

def filter_by_persistence(persistence_diagram, threshold=0.1):
    \"\"\"
    Filtra caracter√≠sticas topol√≥gicas por persistencia m√≠nima.

    Arguments:
    persistence_diagram -- array (n_features, 2) con (birth, death)
    threshold -- persistencia m√≠nima para mantener caracter√≠stica

    Returns:
    filtered_diagram -- diagrama filtrado
    n_removed -- n√∫mero de caracter√≠sticas removidas
    \"\"\"

    # 1. Calcular persistencia para cada caracter√≠stica
    # (approx. 1 line)
    # Persistencia = death - birth
    # YOUR CODE STARTS HERE

    # YOUR CODE ENDS HERE

    # 2. Identificar caracter√≠sticas significativas
    # (approx. 2 lines)
    # Mantener solo donde persistencia >= threshold Y death es finito
    # YOUR CODE STARTS HERE


    # YOUR CODE ENDS HERE

    # 3. Filtrar diagrama
    # (approx. 1 line)
    # YOUR CODE STARTS HERE

    # YOUR CODE ENDS HERE

    # 4. Contar cu√°ntas se removieron
    # (approx. 1 line)
    # YOUR CODE STARTS HERE

    # YOUR CODE ENDS HERE

    return filtered_diagram, n_removed"""))

new_cells.append(nbf.v4.new_code_cell("""# Test del Ejercicio 6
# Generar diagrama de prueba
result = ripser(circle_points, maxdim=1)
dgm_h1 = result['dgms'][1]

print(f"Diagrama original (H‚ÇÅ): {len(dgm_h1)} caracter√≠sticas")

# Filtrar con diferentes thresholds
filtered_01, n_removed_01 = filter_by_persistence(dgm_h1, threshold=0.1)
filtered_02, n_removed_02 = filter_by_persistence(dgm_h1, threshold=0.2)

print(f"\\nCon threshold 0.1: {len(filtered_01)} caracter√≠sticas ({n_removed_01} removidas)")
print(f"Con threshold 0.2: {len(filtered_02)} caracter√≠sticas ({n_removed_02} removidas)")

# Visualizar
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Original
from persim import plot_diagrams
plot_diagrams([dgm_h1], ax=axes[0])
axes[0].set_title('Diagrama Original', fontsize=12, fontweight='bold')

# Filtrado
plot_diagrams([filtered_02], ax=axes[1])
axes[1].set_title(f'Diagrama Filtrado (threshold=0.2)\\n{len(filtered_02)} caracter√≠sticas persistentes',
                 fontsize=12, fontweight='bold')

plt.tight_layout()
plt.show()

# Test autom√°tico
from tda_tests import test_filter_by_persistence
test_filter_by_persistence(filter_by_persistence)"""))

new_cells.append(nbf.v4.new_markdown_cell("""<div style="background-color:#fff3cd; padding:15px; border-left:5px solid #ffc107; margin: 20px 0;">

**‚öôÔ∏è Uso Pr√°ctico:**

- **Preprocesamiento:** Eliminar ruido antes de an√°lisis
- **Visualizaci√≥n:** Diagramas m√°s limpios y legibles
- **Machine Learning:** Features m√°s robustas
- **Regla general:** threshold = 10-20% del rango de distancias

</div>

---"""))

# ========== EJERCICIO 7: Entrop√≠a de persistencia ==========
new_cells.append(nbf.v4.new_markdown_cell("""### Ejercicio 7 - compute_persistence_entropy

Calcula la entrop√≠a de persistencia como medida de complejidad.

**Concepto:** La entrop√≠a mide cu√°n uniforme es la distribuci√≥n de persistencias.
- **Alta entrop√≠a:** Muchas caracter√≠sticas con persistencias similares
- **Baja entrop√≠a:** Pocas caracter√≠sticas dominan

**F√≥rmula:** $E = -\\sum p_i \\log(p_i)$ donde $p_i = \\frac{\\text{persistence}_i}{\\sum \\text{persistence}_j}$

**Aplicaci√≥n:** Cuantificar complejidad estructural de estados cerebrales"""))

new_cells.append(nbf.v4.new_code_cell("""# EJERCICIO 7: Entrop√≠a de Persistencia

def compute_persistence_entropy(persistence_diagram):
    \"\"\"
    Calcula entrop√≠a de persistencia como medida de complejidad.

    Arguments:
    persistence_diagram -- array (n_features, 2) con (birth, death)

    Returns:
    entropy -- entrop√≠a de persistencia
    \"\"\"

    # 1. Filtrar caracter√≠sticas infinitas
    # (approx. 2 lines)
    # Mantener solo donde death es finito
    # YOUR CODE STARTS HERE


    # YOUR CODE ENDS HERE

    # 2. Calcular persistencias
    # (approx. 1 line)
    # YOUR CODE STARTS HERE

    # YOUR CODE ENDS HERE

    # 3. Normalizar a probabilidades
    # (approx. 2 lines)
    # p_i = persistence_i / sum(persistences)
    # YOUR CODE STARTS HERE


    # YOUR CODE ENDS HERE

    # 4. Calcular entrop√≠a
    # (approx. 3 lines)
    # E = -sum(p * log(p)) donde p > 0
    # YOUR CODE STARTS HERE



    # YOUR CODE ENDS HERE

    return entropy"""))

new_cells.append(nbf.v4.new_code_cell("""# Test del Ejercicio 7
# Comparar entrop√≠a de diferentes estados
result_resting = ripser(resting_state, maxdim=1)
result_active = ripser(active_state, maxdim=1)

entropy_resting_h1 = compute_persistence_entropy(result_resting['dgms'][1])
entropy_active_h1 = compute_persistence_entropy(result_active['dgms'][1])

print("Entrop√≠a de Persistencia (H‚ÇÅ):")
print(f"\\nEstado de reposo: {entropy_resting_h1:.3f}")
print(f"Estado activo:    {entropy_active_h1:.3f}")

diff = abs(entropy_resting_h1 - entropy_active_h1)
print(f"\\nDiferencia: {diff:.3f}")

if entropy_resting_h1 > entropy_active_h1:
    print("‚Üí Estado de reposo tiene mayor complejidad topol√≥gica (H‚ÇÅ)")
else:
    print("‚Üí Estado activo tiene mayor complejidad topol√≥gica (H‚ÇÅ)")

# Calcular tambi√©n para H‚ÇÇ
if len(result_resting['dgms']) > 2:
    entropy_resting_h2 = compute_persistence_entropy(result_resting['dgms'][2])
    entropy_active_h2 = compute_persistence_entropy(result_active['dgms'][2])
    print(f"\\nEntrop√≠a H‚ÇÇ (cavidades):")
    print(f"  Reposo: {entropy_resting_h2:.3f}")
    print(f"  Activo: {entropy_active_h2:.3f}")

# Test autom√°tico
from tda_tests import test_compute_persistence_entropy
test_compute_persistence_entropy(compute_persistence_entropy)"""))

new_cells.append(nbf.v4.new_markdown_cell("""<div style="background-color:#e8f5e9; padding:15px; border-left:5px solid #4caf50; margin: 20px 0;">

**üí° Interpretaci√≥n Cl√≠nica:**

- **Alta entrop√≠a** ‚Üí Complejidad distribuida (muchas estructuras similares)
- **Baja entrop√≠a** ‚Üí Pocas estructuras dominantes
- √ötil para clasificar **trastornos neurol√≥gicos**:
  - Alzheimer: Reducci√≥n en entrop√≠a H‚ÇÅ (p√©rdida de ciclos funcionales)
  - Esquizofrenia: Alteraci√≥n en entrop√≠a H‚ÇÇ (organizaci√≥n jer√°rquica)
- Puede usarse como **biomarcador diagn√≥stico**

</div>

---"""))

# Actualizar tabla de contenidos
for i, cell in enumerate(nb.cells):
    if cell.cell_type == 'markdown' and '<a name=\'toc\'></a>' in cell.source:
        # Actualizar TOC
        nb.cells[i].source = """<a name='toc'></a>
## üìö Tabla de Contenidos

- [1 - Setup e Importaciones](#1)
- [2 - Conceptos Fundamentales de Topolog√≠a](#2)
- [3 - Complejos Simpliciales](#3)
    - [Ejercicio 1 - build_simplicial_complex](#ex-1)
- [4 - N√∫meros de Betti y Homolog√≠a](#4)
    - [Ejercicio 2 - compute_betti_numbers](#ex-2)
- [5 - Aplicaci√≥n: Redes Neuronales](#5)
    - [Ejercicio 3 - generate_neural_network](#ex-3)
- [6 - Aplicaci√≥n: Estados Cerebrales](#6)
    - [Ejercicio 4 - generate_brain_state](#ex-4)
- [6.5 - Ejercicios Avanzados](#6.5)
    - [Ejercicio 5 - compare_topological_features](#ex-5)
    - [Ejercicio 6 - filter_by_persistence](#ex-6)
    - [Ejercicio 7 - compute_persistence_entropy](#ex-7)
- [7 - Resumen y Pr√≥ximos Pasos](#7)

---"""
        break

# Insertar secci√≥n de ejercicios avanzados
header_cell = nbf.v4.new_markdown_cell("""<a name='6.5'></a>
## 6.5 - Ejercicios Avanzados: An√°lisis Topol√≥gico Profundo

[Volver al √≠ndice](#toc)

Ahora aplicaremos t√©cnicas m√°s avanzadas para comparar y analizar caracter√≠sticas topol√≥gicas.

---""")

# Insertar nuevas celdas antes del resumen
nb.cells.insert(insert_idx, header_cell)
for i, cell in enumerate(new_cells):
    nb.cells.insert(insert_idx + 1 + i, cell)

# Guardar notebook expandido
with open('notebooks/01_Introduccion_TDA_v2.ipynb', 'w') as f:
    nbf.write(nb, f)

print("‚úÖ Tutorial 1 expandido: 7 ejercicios totales (agregados 3 nuevos)")
print("   ‚Ä¢ Ejercicio 5: compare_topological_features")
print("   ‚Ä¢ Ejercicio 6: filter_by_persistence")
print("   ‚Ä¢ Ejercicio 7: compute_persistence_entropy")
