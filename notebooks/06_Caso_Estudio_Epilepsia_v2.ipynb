{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7818aecf",
   "metadata": {},
   "source": [
    "# Tutorial 6: Caso de Estudio End-to-End (Versi√≥n Interactiva)\n",
    "\n",
    "## Detecci√≥n de Crisis Epil√©pticas con TDA\n",
    "\n",
    "**Autor:** MARK-126  \n",
    "**Nivel:** Avanzado  \n",
    "**Tiempo estimado:** 180-240 minutos\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Objetivos del Caso de Estudio\n",
    "\n",
    "1. ‚úÖ Trabajar con datos reales de EEG cl√≠nico\n",
    "2. ‚úÖ Pipeline completo de preprocesamiento profesional\n",
    "3. ‚úÖ Aplicar TDA a problema m√©dico real\n",
    "4. ‚úÖ Construir clasificador con caracter√≠sticas topol√≥gicas\n",
    "5. ‚úÖ Evaluar con m√©tricas cl√≠nicas rigurosas\n",
    "6. ‚úÖ Interpretar resultados neurobiol√≥gicamente\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Nota sobre Ejercicios\n",
    "\n",
    "Este notebook contiene **3 ejercicios interactivos avanzados** del pipeline completo.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1ef0cb",
   "metadata": {},
   "source": [
    "<a name='toc'></a>\n",
    "## üìö Tabla de Contenidos\n",
    "\n",
    "- [1 - Setup e Importaciones](#1)\n",
    "- [2 - Generaci√≥n de Datos EEG](#2)\n",
    "- [3 - Preprocesamiento](#3)\n",
    "    - [Ejercicio 1 - preprocess_eeg](#ex-1)\n",
    "- [4 - Pipeline TDA](#4)\n",
    "- [5 - Extracci√≥n de Caracter√≠sticas](#5)\n",
    "    - [Ejercicio 2 - extract_comprehensive_features](#ex-2)\n",
    "- [6 - Machine Learning](#6)\n",
    "    - [Ejercicio 3 - train_topological_classifier](#ex-3)\n",
    "- [7 - Evaluaci√≥n y Resumen](#7)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdbaac3",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Setup e Importaciones\n",
    "\n",
    "[Volver al √≠ndice](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a39c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from ripser import ripser\n",
    "from scipy import signal\n",
    "from scipy.stats import zscore, poisson\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "import pandas as pd\n",
    "\n",
    "from tda_tests import (\n",
    "    test_preprocess_eeg_tutorial6,\n",
    "    test_extract_comprehensive_features_tutorial6,\n",
    "    test_train_topological_classifier\n",
    ")\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "np.random.seed(42)\n",
    "print(\"‚úÖ Setup completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88fee21",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Generaci√≥n de Datos EEG Sint√©ticos\n",
    "\n",
    "[Volver al √≠ndice](#toc)\n",
    "\n",
    "Generamos EEG que simula estados ictal (crisis) e interictal (normal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a31ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_realistic_eeg_segment(duration=10, fs=256, state='interictal', n_channels=23):\n",
    "    n_samples = int(duration * fs)\n",
    "    t = np.linspace(0, duration, n_samples)\n",
    "    eeg_data = np.zeros((n_channels, n_samples))\n",
    "    \n",
    "    for ch in range(n_channels):\n",
    "        if state == 'interictal':\n",
    "            alpha = 0.3 * np.sin(2 * np.pi * np.random.uniform(8, 13) * t)\n",
    "            beta = 0.2 * np.sin(2 * np.pi * np.random.uniform(13, 30) * t)\n",
    "            theta = 0.15 * np.sin(2 * np.pi * np.random.uniform(4, 8) * t)\n",
    "            noise = 0.3 * np.random.randn(n_samples)\n",
    "            eeg_data[ch] = alpha + beta + theta + noise\n",
    "        elif state == 'ictal':\n",
    "            seizure_freq = np.random.uniform(3, 5)\n",
    "            spike_wave = 2.5 * np.sin(2 * np.pi * seizure_freq * t)\n",
    "            harmonics = 0.8 * np.sin(2 * np.pi * 2 * seizure_freq * t)\n",
    "            harmonics += 0.4 * np.sin(2 * np.pi * 3 * seizure_freq * t)\n",
    "            hfo = 0.3 * np.sin(2 * np.pi * np.random.uniform(80, 200) * t)\n",
    "            phase_offset = np.random.uniform(0, 0.2)\n",
    "            noise = 0.15 * np.random.randn(n_samples)\n",
    "            eeg_data[ch] = spike_wave + harmonics + hfo + noise\n",
    "            eeg_data[ch] = np.roll(eeg_data[ch], int(phase_offset * fs))\n",
    "    \n",
    "    return eeg_data, t\n",
    "\n",
    "print(\"üß† Generando datos EEG...\\n\")\n",
    "eeg_interictal, t = generate_realistic_eeg_segment(duration=10, state='interictal')\n",
    "eeg_ictal, _ = generate_realistic_eeg_segment(duration=10, state='ictal')\n",
    "print(f\"‚úÖ Shape: {eeg_interictal.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea96bba9",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3 - Preprocesamiento Profesional\n",
    "\n",
    "[Volver al √≠ndice](#toc)\n",
    "\n",
    "<a name='ex-1'></a>\n",
    "### Ejercicio 1 - preprocess_eeg\n",
    "\n",
    "Implementa el pipeline de preprocesamiento profesional para EEG cl√≠nico.\n",
    "\n",
    "**Pasos:**\n",
    "1. Filtro bandpass (0.5-50 Hz)\n",
    "2. Notch filter (60 Hz)\n",
    "3. Common average reference (CAR)\n",
    "4. Normalizaci√≥n z-score por canal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83267547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO 1: Preprocesar EEG\n",
    "\n",
    "def preprocess_eeg(eeg_data, fs=256):\n",
    "    \"\"\"\n",
    "    Pipeline de preprocesamiento profesional para EEG.\n",
    "    \n",
    "    Arguments:\n",
    "    eeg_data -- array (n_channels, n_samples)\n",
    "    fs -- frecuencia de muestreo (Hz)\n",
    "    \n",
    "    Returns:\n",
    "    eeg_normalized -- EEG preprocesado\n",
    "    \"\"\"\n",
    "    n_channels, n_samples = eeg_data.shape\n",
    "    \n",
    "    # 1. Filtro bandpass (0.5-50 Hz)\n",
    "    # Usar scipy.signal.butter y filtfilt\n",
    "    # (approx. 5 lines)\n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    # 2. Notch filter (60 Hz)\n",
    "    # Usar scipy.signal.iirnotch y filtfilt\n",
    "    # (approx. 3 lines)\n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    \n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    # 3. Common average reference\n",
    "    # Restar el promedio de todos los canales\n",
    "    # (approx. 2 lines)\n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    # 4. Normalizaci√≥n z-score por canal\n",
    "    # Usar scipy.stats.zscore en cada canal\n",
    "    # (approx. 3 lines)\n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    \n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    return eeg_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c77c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Ejercicio 1\n",
    "eeg_prep = preprocess_eeg(eeg_interictal)\n",
    "print(f\"‚úÖ Preprocesado: {eeg_prep.shape}\")\n",
    "test_preprocess_eeg_tutorial6(preprocess_eeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2ea538",
   "metadata": {},
   "source": [
    "<a name='5'></a>\n",
    "## 5 - Extracci√≥n de Caracter√≠sticas Topol√≥gicas\n",
    "\n",
    "[Volver al √≠ndice](#toc)\n",
    "\n",
    "<a name='ex-2'></a>\n",
    "### Ejercicio 2 - extract_comprehensive_features\n",
    "\n",
    "Extrae caracter√≠sticas TDA + espectrales + temporales para ML.\n",
    "\n",
    "**Incluir:**\n",
    "- TDA: n_cycles, max_persistence, mean_persistence, entropy\n",
    "- Espectrales: potencia por banda, frecuencia dominante\n",
    "- Temporales: media, std, skewness, kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb82037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO 2: Extraer Caracter√≠sticas Completas\n",
    "\n",
    "def extract_comprehensive_features(eeg_segment, fs=256):\n",
    "    \"\"\"\n",
    "    Extrae caracter√≠sticas completas: TDA + espectrales + temporales.\n",
    "    \n",
    "    Arguments:\n",
    "    eeg_segment -- array (n_channels, n_samples)\n",
    "    fs -- frecuencia de muestreo\n",
    "    \n",
    "    Returns:\n",
    "    features -- diccionario con todas las caracter√≠sticas\n",
    "    \"\"\"\n",
    "    from scipy.fft import fft, fftfreq\n",
    "    \n",
    "    features = {}\n",
    "    eeg_prep = preprocess_eeg(eeg_segment, fs)\n",
    "    signal = eeg_prep[0]  # Usar primer canal\n",
    "    \n",
    "    # === TDA ===\n",
    "    # Crear embedding de Takens simple\n",
    "    delay = 10\n",
    "    dim = 3\n",
    "    embedded = np.column_stack([signal[i*delay:(len(signal)-(dim-1-i)*delay)] \n",
    "                                for i in range(dim)])\n",
    "    \n",
    "    # Subsampling para eficiencia\n",
    "    if len(embedded) > 500:\n",
    "        indices = np.random.choice(len(embedded), 500, replace=False)\n",
    "        embedded = embedded[indices]\n",
    "    \n",
    "    # Calcular persistencia\n",
    "    result = ripser(embedded, maxdim=1, thresh=5.0)\n",
    "    dgm1 = result['dgms'][1]\n",
    "    \n",
    "    # Extraer caracter√≠sticas de H‚ÇÅ\n",
    "    # (approx. 10 lines)\n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    # === ESPECTRALES ===\n",
    "    # Calcular FFT y potencia por bandas\n",
    "    # (approx. 8 lines)\n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    # === TEMPORALES ===\n",
    "    # Estad√≠sticas b√°sicas de la se√±al\n",
    "    # (approx. 5 lines)\n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648b63e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Ejercicio 2\n",
    "features_inter = extract_comprehensive_features(eeg_interictal)\n",
    "features_ictal = extract_comprehensive_features(eeg_ictal)\n",
    "print(f\"‚úÖ Features extra√≠das: {len(features_inter)} caracter√≠sticas\")\n",
    "print(f\"   Interictal - ciclos: {features_inter.get('n_cycles', 0)}\")\n",
    "print(f\"   Ictal - ciclos: {features_ictal.get('n_cycles', 0)}\")\n",
    "test_extract_comprehensive_features_tutorial6(extract_comprehensive_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d522798c",
   "metadata": {},
   "source": [
    "<a name='6'></a>\n",
    "## 6 - Machine Learning\n",
    "\n",
    "[Volver al √≠ndice](#toc)\n",
    "\n",
    "<a name='ex-3'></a>\n",
    "### Ejercicio 3 - train_topological_classifier\n",
    "\n",
    "Entrena clasificador usando caracter√≠sticas topol√≥gicas.\n",
    "\n",
    "**Pasos:**\n",
    "1. Dividir datos en train/test\n",
    "2. Normalizar caracter√≠sticas\n",
    "3. Entrenar Random Forest\n",
    "4. Evaluar con m√©tricas cl√≠nicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c958097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO 3: Entrenar Clasificador\n",
    "\n",
    "def train_topological_classifier(X, y, test_size=0.3):\n",
    "    \"\"\"\n",
    "    Entrena y eval√∫a clasificador topol√≥gico.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- caracter√≠sticas (n_samples, n_features)\n",
    "    y -- etiquetas (n_samples,)\n",
    "    test_size -- proporci√≥n de test\n",
    "    \n",
    "    Returns:\n",
    "    clf -- clasificador entrenado\n",
    "    results -- diccionario con m√©tricas\n",
    "    \"\"\"\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # 1. Dividir datos\n",
    "    # (approx. 2 lines)\n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    # 2. Normalizar\n",
    "    # (approx. 3 lines)\n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    \n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    # 3. Entrenar Random Forest\n",
    "    # (approx. 2 lines)\n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    # 4. Predicciones y m√©tricas\n",
    "    # (approx. 5 lines)\n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    return clf, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f81e035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar dataset completo\n",
    "print(\"üèóÔ∏è Construyendo dataset...\\n\")\n",
    "X_data = []\n",
    "y_data = []\n",
    "\n",
    "for i in range(30):\n",
    "    eeg, _ = generate_realistic_eeg_segment(duration=10, state='interictal')\n",
    "    features = extract_comprehensive_features(eeg)\n",
    "    X_data.append(list(features.values()))\n",
    "    y_data.append(0)\n",
    "\n",
    "for i in range(30):\n",
    "    eeg, _ = generate_realistic_eeg_segment(duration=10, state='ictal')\n",
    "    features = extract_comprehensive_features(eeg)\n",
    "    X_data.append(list(features.values()))\n",
    "    y_data.append(1)\n",
    "\n",
    "X = np.array(X_data)\n",
    "y = np.array(y_data)\n",
    "print(f\"‚úÖ Dataset: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13877dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Ejercicio 3\n",
    "clf, results = train_topological_classifier(X, y)\n",
    "print(f\"\\n‚úÖ Accuracy: {results.get('accuracy', 0):.2%}\")\n",
    "test_train_topological_classifier(train_topological_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c091242a",
   "metadata": {},
   "source": [
    "<a name='7'></a>\n",
    "## 7 - Resumen\n",
    "\n",
    "[Volver al √≠ndice](#toc)\n",
    "\n",
    "<div style=\"background-color:#e3f2fd; padding:15px; border-left:5px solid #2196f3;\">\n",
    "\n",
    "**üí° Lo que aprendimos:**\n",
    "\n",
    "- **Preprocesamiento profesional** es cr√≠tico\n",
    "- **TDA** aporta caracter√≠sticas √∫nicas\n",
    "- **Pipeline completo** funciona en datos reales\n",
    "- **Clasificaci√≥n** con alta precisi√≥n es posible\n",
    "- **Aplicaci√≥n cl√≠nica** promete mejorar diagn√≥stico\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ ¬°Felicitaciones!\n",
    "\n",
    "Completaste el caso de estudio end-to-end. Ahora dominas el pipeline completo de TDA aplicado.\n",
    "\n",
    "---\n",
    "\n",
    "**Autor:** MARK-126  \n",
    "**Licencia:** MIT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a7864b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Ejercicio 4 - feature_importance_analysis\n",
    "\n",
    "Entender qu√© **features topol√≥gicas** son m√°s discriminativas para detectar epilepsia permite interpretabilidad cl√≠nica y optimizaci√≥n del modelo. Features como Betti numbers espec√≠ficos o rangos de persistencia pueden tener significado neurobiol√≥gico.\n",
    "\n",
    "**Aplicaci√≥n cl√≠nica:** Identificar biomarcadores interpretables, optimizar panel de features.\n",
    "\n",
    "**Tu tarea:** Implementa un an√°lisis completo de importancia de features usando m√∫ltiples m√©todos.\n",
    "\n",
    "**Dificultad:** ‚≠ê‚≠ê‚≠ê Avanzado\n",
    "**Tiempo estimado:** 20-25 minutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc08130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_analysis():\n",
    "    \"\"\"\n",
    "    Analiza importancia de features topol√≥gicas para clasificaci√≥n.\n",
    "\n",
    "    Par√°metros:\n",
    "    -----------\n",
    "    X : array, shape (n_samples, n_features)\n",
    "        Matriz de features TDA\n",
    "    y : array, shape (n_samples,)\n",
    "        Labels (0=normal, 1=ictal)\n",
    "    feature_names : list\n",
    "        Nombres de las features\n",
    "\n",
    "    Retorna:\n",
    "    --------\n",
    "    importance_scores : dict\n",
    "        Diccionario con scores de diferentes m√©todos:\n",
    "        - 'random_forest': Importancia de Random Forest\n",
    "        - 'permutation': Importancia por permutaci√≥n\n",
    "        - 'mutual_info': Informaci√≥n mutua\n",
    "    top_features : list\n",
    "        Top 10 features m√°s importantes (nombres)\n",
    "    \"\"\"\n",
    "    # YOUR CODE STARTS HERE\n",
    "    # (approx. 20-25 lines)\n",
    "    # Hint 1: Entrena RandomForestClassifier y extrae feature_importances_\n",
    "    # Hint 2: Calcula permutation importance con sklearn.inspection\n",
    "    # Hint 3: Calcula mutual information con sklearn.feature_selection\n",
    "    # Hint 4: Normaliza todos los scores a [0, 1]\n",
    "    # Hint 5: Combina scores (promedio o ranking fusion)\n",
    "    # Hint 6: Retorna top 10 features por importancia combinada\n",
    "\n",
    "    # YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e43061f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test autom√°tico\n",
    "from notebooks.tda_tests import test_feature_importance_analysis\n",
    "test_feature_importance_analysis(feature_importance_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b658b6f5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Ejercicio 5 - cross_validate_pipeline\n",
    "\n",
    "La **validaci√≥n cruzada rigurosa** es esencial para estimar el desempe√±o real del sistema en datos nuevos. Usar estratificaci√≥n y validaci√≥n temporal evita sobreajuste y produce estimaciones realistas.\n",
    "\n",
    "**Aplicaci√≥n:** Validaci√≥n pre-cl√≠nica antes de deployment, reporte de desempe√±o confiable.\n",
    "\n",
    "**Tu tarea:** Implementa un pipeline completo de validaci√≥n cruzada con m√∫ltiples m√©tricas.\n",
    "\n",
    "**Dificultad:** ‚≠ê‚≠ê‚≠ê Avanzado\n",
    "**Tiempo estimado:** 20-25 minutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb240fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_pipeline():\n",
    "    \"\"\"\n",
    "    Valida pipeline completo de detecci√≥n usando cross-validation.\n",
    "\n",
    "    Par√°metros:\n",
    "    -----------\n",
    "    eeg_data : array, shape (n_epochs, n_channels, n_samples)\n",
    "        Datos EEG crudos\n",
    "    labels : array, shape (n_epochs,)\n",
    "        Labels verdaderas\n",
    "    cv_folds : int\n",
    "        N√∫mero de folds para cross-validation (default: 5)\n",
    "\n",
    "    Retorna:\n",
    "    --------\n",
    "    cv_results : dict\n",
    "        Resultados de validaci√≥n cruzada:\n",
    "        - 'accuracy': Accuracy promedio ¬± std\n",
    "        - 'precision': Precision promedio ¬± std\n",
    "        - 'recall': Recall promedio ¬± std\n",
    "        - 'f1': F1-score promedio ¬± std\n",
    "        - 'roc_auc': ROC-AUC promedio ¬± std\n",
    "        - 'confusion_matrices': Lista de matrices de confusi√≥n\n",
    "    trained_model : objeto\n",
    "        Modelo final entrenado en todos los datos\n",
    "    \"\"\"\n",
    "    # YOUR CODE STARTS HERE\n",
    "    # (approx. 25-30 lines)\n",
    "    # Hint 1: Preprocesa todos los epochs de EEG (filtros, CAR, normalizaci√≥n)\n",
    "    # Hint 2: Extrae features TDA + espectrales de cada epoch\n",
    "    # Hint 3: Usa StratifiedKFold para splits balanceados\n",
    "    # Hint 4: Para cada fold:\n",
    "    #         - Entrena pipeline en train set\n",
    "    #         - Eval√∫a en validation set\n",
    "    #         - Calcula todas las m√©tricas\n",
    "    # Hint 5: Agrega resultados y calcula media ¬± std\n",
    "    # Hint 6: Entrena modelo final en todos los datos\n",
    "    # Hint 7: Retorna resultados completos de CV\n",
    "\n",
    "    # YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c309515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test autom√°tico\n",
    "from notebooks.tda_tests import test_cross_validate_pipeline\n",
    "test_cross_validate_pipeline(cross_validate_pipeline)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
