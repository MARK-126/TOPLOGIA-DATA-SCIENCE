{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2: Homolog√≠a Persistente Avanzada\n",
    "\n",
    "## Aplicaciones a Patrones Neuronales\n",
    "\n",
    "**Autor:** MARK-126  \n",
    "**Nivel:** Intermedio-Avanzado  \n",
    "**Tiempo estimado:** 120-150 minutos\n",
    "\n",
    "---\n",
    "\n",
    "## Objetivos de Aprendizaje\n",
    "\n",
    "1. ‚úÖ Dominar diferentes tipos de filtraciones (Rips, Alpha, ƒåech)\n",
    "2. ‚úÖ Calcular distancias entre diagramas de persistencia\n",
    "3. ‚úÖ Aplicar TDA a spike trains neuronales\n",
    "4. ‚úÖ Optimizar c√°lculos para datasets grandes\n",
    "5. ‚úÖ Interpretar resultados en contexto neurobiol√≥gico\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Repaso y Motivaci√≥n\n",
    "\n",
    "En el Tutorial 1 aprendimos los fundamentos de TDA. Ahora vamos m√°s profundo:\n",
    "\n",
    "### ¬øPor qu√© necesitamos m√©todos avanzados?\n",
    "\n",
    "En neurociencias nos encontramos con:\n",
    "- **Datos masivos:** Miles de neuronas registradas simult√°neamente\n",
    "- **Alta dimensi√≥n:** Espacios de activaci√≥n de 100+ dimensiones\n",
    "- **Comparaciones:** Necesitamos cuantificar similitud entre estados\n",
    "- **Temporalidad:** Datos din√°micos que evolucionan en el tiempo\n",
    "\n",
    "### Preguntas que responderemos:\n",
    "\n",
    "1. ¬øC√≥mo comparar la topolog√≠a de dos estados cerebrales?\n",
    "2. ¬øQu√© filtraci√≥n es mejor para datos neuronales?\n",
    "3. ¬øC√≥mo analizar patrones temporales de activaci√≥n?\n",
    "4. ¬øQu√© caracter√≠sticas topol√≥gicas son m√°s informativas?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# TDA avanzado\n",
    "from ripser import ripser\n",
    "from persim import plot_diagrams, bottleneck, sliced_wasserstein\n",
    "import gudhi as gd\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "from gtda.diagrams import Amplitude, PersistenceEntropy\n",
    "from gtda.plotting import plot_diagram\n",
    "\n",
    "# Procesamiento de datos\n",
    "from scipy.spatial.distance import pdist, squareform, euclidean\n",
    "from scipy.stats import poisson\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Visualizaci√≥n avanzada\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "\n",
    "# Configuraci√≥n\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context(\"notebook\", font_scale=1.2)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Bibliotecas importadas correctamente\")\n",
    "print(f\"üì¶ GUDHI version: {gd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Tipos de Filtraciones\n",
    "\n",
    "### 2.1 ¬øQu√© es una filtraci√≥n?\n",
    "\n",
    "Una **filtraci√≥n** es una secuencia de complejos simpliciales anidados:\n",
    "$$\\emptyset = K_0 \\subseteq K_1 \\subseteq K_2 \\subseteq \\ldots \\subseteq K_n = K$$\n",
    "\n",
    "Cada tipo de filtraci√≥n tiene **ventajas espec√≠ficas** para diferentes tipos de datos.\n",
    "\n",
    "### 2.2 Comparaci√≥n de Filtraciones\n",
    "\n",
    "| Filtraci√≥n | Ventaja | Desventaja | Aplicaci√≥n Neural |\n",
    "|-----------|---------|------------|-------------------|\n",
    "| **Vietoris-Rips** | R√°pido, simple | Puede a√±adir simplejos espurios | An√°lisis de conectividad general |\n",
    "| **ƒåech** | Te√≥ricamente √≥ptimo | Computacionalmente costoso | Estudios te√≥ricos |\n",
    "| **Alpha** | Geom√©tricamente preciso | Solo para baja dimensi√≥n | Visualizaci√≥n de subredes |\n",
    "| **Filtraci√≥n de grafo** | Natural para redes | Requiere estructura de grafo | Conectomas cerebrales |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implementaci√≥n Pr√°ctica: Comparaci√≥n de Filtraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_filtrations(points, max_dim=2):\n",
    "    \"\"\"\n",
    "    Compara diferentes tipos de filtraciones en los mismos datos.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    points : numpy array\n",
    "        Puntos a analizar (n_points x n_dimensions)\n",
    "    max_dim : int\n",
    "        Dimensi√≥n m√°xima de homolog√≠a\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # 1. Vietoris-Rips (usando ripser - r√°pido)\n",
    "    print(\"üîÑ Calculando Vietoris-Rips...\")\n",
    "    import time\n",
    "    start = time.time()\n",
    "    rips_result = ripser(points, maxdim=max_dim)\n",
    "    rips_time = time.time() - start\n",
    "    results['Vietoris-Rips'] = {\n",
    "        'diagrams': rips_result['dgms'],\n",
    "        'time': rips_time\n",
    "    }\n",
    "    \n",
    "    # 2. Alpha complex (usando GUDHI)\n",
    "    if points.shape[1] <= 3:  # Alpha solo funciona bien en 2D/3D\n",
    "        print(\"üîÑ Calculando Alpha complex...\")\n",
    "        start = time.time()\n",
    "        alpha_complex = gd.AlphaComplex(points=points)\n",
    "        simplex_tree = alpha_complex.create_simplex_tree()\n",
    "        persistence = simplex_tree.persistence()\n",
    "        \n",
    "        # Convertir a formato de diagrama\n",
    "        alpha_diagrams = [[] for _ in range(max_dim + 1)]\n",
    "        for dim, (birth, death) in persistence:\n",
    "            if dim <= max_dim:\n",
    "                alpha_diagrams[dim].append([birth, death])\n",
    "        \n",
    "        alpha_diagrams = [np.array(d) if len(d) > 0 else np.array([]).reshape(0, 2) \n",
    "                         for d in alpha_diagrams]\n",
    "        alpha_time = time.time() - start\n",
    "        \n",
    "        results['Alpha'] = {\n",
    "            'diagrams': alpha_diagrams,\n",
    "            'time': alpha_time\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Generar datos de prueba: red neuronal sint√©tica\n",
    "print(\"üß† Generando red neuronal sint√©tica...\\n\")\n",
    "n_neurons = 50\n",
    "neural_data_2d = np.random.randn(n_neurons, 2) * 0.5\n",
    "neural_data_2d[:20] += np.array([2, 0])  # Comunidad 1\n",
    "neural_data_2d[20:35] += np.array([0, 2])  # Comunidad 2\n",
    "# Comunidad 3 en el origen\n",
    "\n",
    "# Comparar filtraciones\n",
    "results = compare_filtrations(neural_data_2d, max_dim=1)\n",
    "\n",
    "# Visualizar resultados\n",
    "fig, axes = plt.subplots(1, len(results) + 1, figsize=(18, 5))\n",
    "\n",
    "# Plot 1: Datos originales\n",
    "axes[0].scatter(neural_data_2d[:, 0], neural_data_2d[:, 1], \n",
    "                c='blue', s=100, alpha=0.6, edgecolors='black')\n",
    "axes[0].set_title('Red Neuronal\\n(3 comunidades)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_aspect('equal')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plots de diagramas\n",
    "for idx, (name, result) in enumerate(results.items(), start=1):\n",
    "    plot_diagrams(result['diagrams'], ax=axes[idx])\n",
    "    axes[idx].set_title(f'{name}\\n(tiempo: {result[\"time\"]:.3f}s)', \n",
    "                       fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ An√°lisis completado\")\n",
    "print(\"\\nüìä Tiempos de c√≥mputo:\")\n",
    "for name, result in results.items():\n",
    "    print(f\"   ‚Ä¢ {name}: {result['time']:.4f} segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Observaciones\n",
    "\n",
    "- **Vietoris-Rips** es generalmente m√°s r√°pido\n",
    "- **Alpha** es m√°s preciso geom√©tricamente pero limitado a 2D/3D\n",
    "- Para datos neuronales de alta dimensi√≥n, **Rips es la elecci√≥n pr√°ctica**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Distancias entre Diagramas de Persistencia\n",
    "\n",
    "### 4.1 ¬øPor qu√© necesitamos distancias?\n",
    "\n",
    "Para comparar estados cerebrales, necesitamos **cuantificar diferencias** entre sus topolog√≠as.\n",
    "\n",
    "### 4.2 Principales M√©tricas\n",
    "\n",
    "#### A. Distancia de Bottleneck\n",
    "$$d_B(D_1, D_2) = \\inf_{\\gamma} \\sup_{p \\in D_1} \\|p - \\gamma(p)\\|_\\infty$$\n",
    "\n",
    "**Interpretaci√≥n:** Peor caso de emparejamiento entre puntos\n",
    "- **Robusta** a outliers\n",
    "- Mide la **m√°xima diferencia** entre caracter√≠sticas\n",
    "\n",
    "#### B. Distancia de Wasserstein\n",
    "$$W_p(D_1, D_2) = \\left(\\inf_{\\gamma} \\sum_{p \\in D_1} \\|p - \\gamma(p)\\|^p\\right)^{1/p}$$\n",
    "\n",
    "**Interpretaci√≥n:** Costo promedio de transporte\n",
    "- **Sensible** a todas las caracter√≠sticas\n",
    "- Mide **diferencia global**\n",
    "\n",
    "#### C. Sliced Wasserstein\n",
    "Aproximaci√≥n r√°pida de Wasserstein mediante proyecciones 1D.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Aplicaci√≥n: Comparaci√≥n de Estados Cerebrales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_brain_state_realistic(state_type, n_neurons=100, noise=0.1):\n",
    "    \"\"\"\n",
    "    Genera estados cerebrales sint√©ticos con propiedades realistas.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    state_type : str\n",
    "        'sleep', 'wakeful', 'attention', 'memory'\n",
    "    n_neurons : int\n",
    "        N√∫mero de neuronas\n",
    "    noise : float\n",
    "        Nivel de ruido\n",
    "    \"\"\"\n",
    "    if state_type == 'sleep':\n",
    "        # Sue√±o: activaci√≥n sincronizada, baja dimensionalidad\n",
    "        base = np.random.randn(n_neurons, 1) @ np.random.randn(1, 5)\n",
    "        data = base + np.random.randn(n_neurons, 5) * noise\n",
    "        \n",
    "    elif state_type == 'wakeful':\n",
    "        # Vigilia: activaci√≥n dispersa, alta dimensionalidad\n",
    "        data = np.random.randn(n_neurons, 5) * 1.5\n",
    "        \n",
    "    elif state_type == 'attention':\n",
    "        # Atenci√≥n: subredes focales activas\n",
    "        data = np.zeros((n_neurons, 5))\n",
    "        # Subred atencional activa\n",
    "        data[:n_neurons//3] = np.random.randn(n_neurons//3, 5) * 2.0\n",
    "        # Resto con actividad basal\n",
    "        data[n_neurons//3:] = np.random.randn(2*n_neurons//3, 5) * 0.3\n",
    "        \n",
    "    elif state_type == 'memory':\n",
    "        # Memoria: patrones c√≠clicos (bucles de retroalimentaci√≥n)\n",
    "        theta = np.linspace(0, 4*np.pi, n_neurons)\n",
    "        data = np.column_stack([\n",
    "            np.cos(theta),\n",
    "            np.sin(theta),\n",
    "            np.cos(2*theta) * 0.5,\n",
    "            np.sin(2*theta) * 0.5,\n",
    "            np.random.randn(n_neurons) * noise\n",
    "        ])\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Generar diferentes estados\n",
    "print(\"üß† Generando estados cerebrales sint√©ticos...\\n\")\n",
    "states = {\n",
    "    'Sue√±o': generate_brain_state_realistic('sleep', n_neurons=80),\n",
    "    'Vigilia': generate_brain_state_realistic('wakeful', n_neurons=80),\n",
    "    'Atenci√≥n': generate_brain_state_realistic('attention', n_neurons=80),\n",
    "    'Memoria': generate_brain_state_realistic('memory', n_neurons=80)\n",
    "}\n",
    "\n",
    "# Calcular persistencia para cada estado\n",
    "print(\"‚è≥ Calculando homolog√≠a persistente...\\n\")\n",
    "diagrams = {}\n",
    "for name, data in states.items():\n",
    "    result = ripser(data, maxdim=1, thresh=3.0)\n",
    "    diagrams[name] = result['dgms']\n",
    "    print(f\"‚úì {name}: H‚ÇÄ={len(result['dgms'][0])}, H‚ÇÅ={len(result['dgms'][1])}\")\n",
    "\n",
    "# Calcular matriz de distancias\n",
    "print(\"\\nüìè Calculando distancias entre estados...\\n\")\n",
    "state_names = list(states.keys())\n",
    "n_states = len(state_names)\n",
    "\n",
    "# Matrices para diferentes m√©tricas\n",
    "bottleneck_matrix = np.zeros((n_states, n_states))\n",
    "wasserstein_matrix = np.zeros((n_states, n_states))\n",
    "\n",
    "for i, name1 in enumerate(state_names):\n",
    "    for j, name2 in enumerate(state_names):\n",
    "        if i <= j:\n",
    "            # Usar H‚ÇÅ (ciclos) para comparaci√≥n\n",
    "            d1 = diagrams[name1][1]\n",
    "            d2 = diagrams[name2][1]\n",
    "            \n",
    "            if len(d1) > 0 and len(d2) > 0:\n",
    "                bottleneck_matrix[i, j] = bottleneck(d1, d2)\n",
    "                bottleneck_matrix[j, i] = bottleneck_matrix[i, j]\n",
    "                \n",
    "                wasserstein_matrix[i, j] = sliced_wasserstein(d1, d2)\n",
    "                wasserstein_matrix[j, i] = wasserstein_matrix[i, j]\n",
    "\n",
    "# Visualizar matrices de distancia\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Bottleneck\n",
    "im1 = axes[0].imshow(bottleneck_matrix, cmap='YlOrRd', aspect='auto')\n",
    "axes[0].set_xticks(range(n_states))\n",
    "axes[0].set_yticks(range(n_states))\n",
    "axes[0].set_xticklabels(state_names, rotation=45)\n",
    "axes[0].set_yticklabels(state_names)\n",
    "axes[0].set_title('Distancia de Bottleneck\\n(H‚ÇÅ - Ciclos)', fontsize=14, fontweight='bold')\n",
    "plt.colorbar(im1, ax=axes[0])\n",
    "\n",
    "# Agregar valores en las celdas\n",
    "for i in range(n_states):\n",
    "    for j in range(n_states):\n",
    "        text = axes[0].text(j, i, f'{bottleneck_matrix[i, j]:.2f}',\n",
    "                          ha=\"center\", va=\"center\", color=\"black\", fontweight='bold')\n",
    "\n",
    "# Wasserstein\n",
    "im2 = axes[1].imshow(wasserstein_matrix, cmap='YlGnBu', aspect='auto')\n",
    "axes[1].set_xticks(range(n_states))\n",
    "axes[1].set_yticks(range(n_states))\n",
    "axes[1].set_xticklabels(state_names, rotation=45)\n",
    "axes[1].set_yticklabels(state_names)\n",
    "axes[1].set_title('Distancia de Sliced Wasserstein\\n(H‚ÇÅ - Ciclos)', fontsize=14, fontweight='bold')\n",
    "plt.colorbar(im2, ax=axes[1])\n",
    "\n",
    "# Agregar valores\n",
    "for i in range(n_states):\n",
    "    for j in range(n_states):\n",
    "        text = axes[1].text(j, i, f'{wasserstein_matrix[i, j]:.2f}',\n",
    "                          ha=\"center\", va=\"center\", color=\"black\", fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ An√°lisis de distancias completado\")\n",
    "print(\"\\nüí° Interpretaci√≥n:\")\n",
    "print(\"   ‚Ä¢ Estados con distancia BAJA son topol√≥gicamente similares\")\n",
    "print(\"   ‚Ä¢ Estados con distancia ALTA tienen estructuras diferentes\")\n",
    "print(f\"   ‚Ä¢ Par m√°s similar: {state_names[np.unravel_index(np.argmin(bottleneck_matrix + np.eye(n_states)*999), bottleneck_matrix.shape)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üî¨ An√°lisis Neurobiol√≥gico\n",
    "\n",
    "**Observaciones esperadas:**\n",
    "\n",
    "1. **Sue√±o vs Vigilia:** Distancia alta (estructuras muy diferentes)\n",
    "2. **Atenci√≥n vs Memoria:** Ambos pueden tener ciclos (retroalimentaci√≥n)\n",
    "3. **Vigilia vs Atenci√≥n:** Similar en estructura global, diferente en localizaci√≥n\n",
    "\n",
    "**Significado de ciclos (H‚ÇÅ):**\n",
    "- Sue√±o: Pocos ciclos (actividad sincronizada)\n",
    "- Memoria: Muchos ciclos (bucles de retroalimentaci√≥n)\n",
    "- Vigilia: Ciclos distribuidos uniformemente\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Aplicaci√≥n Real: An√°lisis de Spike Trains\n",
    "\n",
    "### 6.1 ¬øQu√© son los Spike Trains?\n",
    "\n",
    "Los **spike trains** son secuencias de potenciales de acci√≥n (spikes) de neuronas:\n",
    "```\n",
    "Neurona 1: |-----|---------|---|-----|--------|\n",
    "Neurona 2: |---|-----|----------|--|----------|\n",
    "Neurona 3: |--------|---|-----|---------------|--|\n",
    "           0   100   200   300   400   500   600 ms\n",
    "```\n",
    "\n",
    "### 6.2 Construcci√≥n del Espacio de Estados\n",
    "\n",
    "Para aplicar TDA:\n",
    "1. **Ventana deslizante:** Dividir en bins temporales\n",
    "2. **Vector de activaci√≥n:** Contar spikes por neurona en cada bin\n",
    "3. **Espacio de estados:** Cada bin = punto en espacio de dimensi√≥n N (N = # neuronas)\n",
    "4. **Analizar topolog√≠a** de la trayectoria\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_spike_trains(n_neurons=20, duration=1000, base_rate=5.0, \n",
    "                         correlation=0.3, pattern_type='random'):\n",
    "    \"\"\"\n",
    "    Genera spike trains sint√©ticos con diferentes patrones.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_neurons : int\n",
    "        N√∫mero de neuronas\n",
    "    duration : int\n",
    "        Duraci√≥n en ms\n",
    "    base_rate : float\n",
    "        Tasa de disparo base (Hz)\n",
    "    correlation : float\n",
    "        Nivel de correlaci√≥n entre neuronas\n",
    "    pattern_type : str\n",
    "        'random', 'synchronized', 'sequential'\n",
    "    \"\"\"\n",
    "    spike_trains = np.zeros((n_neurons, duration))\n",
    "    \n",
    "    if pattern_type == 'random':\n",
    "        # Actividad aleatoria independiente\n",
    "        for i in range(n_neurons):\n",
    "            spike_trains[i] = poisson.rvs(base_rate/1000, size=duration)\n",
    "            \n",
    "    elif pattern_type == 'synchronized':\n",
    "        # Actividad sincronizada (todas disparan juntas)\n",
    "        common_pattern = poisson.rvs(base_rate/1000, size=duration)\n",
    "        for i in range(n_neurons):\n",
    "            spike_trains[i] = common_pattern * (np.random.rand(duration) < 0.8)  # 80% sync\n",
    "            \n",
    "    elif pattern_type == 'sequential':\n",
    "        # Actividad secuencial (onda de activaci√≥n)\n",
    "        for t in range(duration):\n",
    "            active_neuron = (t // 20) % n_neurons  # Cambia cada 20ms\n",
    "            spike_trains[active_neuron, t] = poisson.rvs(base_rate*3/1000)\n",
    "    \n",
    "    return spike_trains\n",
    "\n",
    "def spike_trains_to_state_space(spike_trains, bin_size=50, stride=25):\n",
    "    \"\"\"\n",
    "    Convierte spike trains a representaci√≥n en espacio de estados.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    spike_trains : numpy array\n",
    "        Matriz de spikes (n_neurons x time)\n",
    "    bin_size : int\n",
    "        Tama√±o de ventana en ms\n",
    "    stride : int\n",
    "        Paso de la ventana deslizante\n",
    "    \"\"\"\n",
    "    n_neurons, duration = spike_trains.shape\n",
    "    n_bins = (duration - bin_size) // stride + 1\n",
    "    \n",
    "    state_space = np.zeros((n_bins, n_neurons))\n",
    "    \n",
    "    for i in range(n_bins):\n",
    "        start = i * stride\n",
    "        end = start + bin_size\n",
    "        state_space[i] = np.sum(spike_trains[:, start:end], axis=1)\n",
    "    \n",
    "    return state_space\n",
    "\n",
    "# Generar spike trains con diferentes patrones\n",
    "print(\"üî• Generando spike trains con diferentes patrones...\\n\")\n",
    "\n",
    "patterns = ['random', 'synchronized', 'sequential']\n",
    "spike_data = {}\n",
    "state_spaces = {}\n",
    "\n",
    "for pattern in patterns:\n",
    "    spikes = generate_spike_trains(n_neurons=15, duration=1000, \n",
    "                                  pattern_type=pattern, base_rate=8.0)\n",
    "    spike_data[pattern] = spikes\n",
    "    state_spaces[pattern] = spike_trains_to_state_space(spikes, bin_size=50, stride=25)\n",
    "\n",
    "# Visualizar spike trains\n",
    "fig, axes = plt.subplots(3, 2, figsize=(18, 12))\n",
    "\n",
    "for idx, pattern in enumerate(patterns):\n",
    "    # Raster plot\n",
    "    ax1 = axes[idx, 0]\n",
    "    for neuron in range(spike_data[pattern].shape[0]):\n",
    "        spike_times = np.where(spike_data[pattern][neuron] > 0)[0]\n",
    "        ax1.scatter(spike_times, [neuron]*len(spike_times), \n",
    "                   c='black', s=1, marker='|')\n",
    "    ax1.set_ylabel('Neurona #', fontsize=11)\n",
    "    ax1.set_xlabel('Tiempo (ms)', fontsize=11)\n",
    "    ax1.set_title(f'Spike Raster: {pattern.capitalize()}', \n",
    "                 fontsize=12, fontweight='bold')\n",
    "    ax1.set_xlim([0, 1000])\n",
    "    \n",
    "    # Espacio de estados (proyecci√≥n 2D con PCA)\n",
    "    ax2 = axes[idx, 1]\n",
    "    if state_spaces[pattern].shape[0] > 2:\n",
    "        pca = PCA(n_components=2)\n",
    "        reduced = pca.fit_transform(state_spaces[pattern])\n",
    "        \n",
    "        ax2.plot(reduced[:, 0], reduced[:, 1], 'o-', \n",
    "                alpha=0.6, linewidth=2, markersize=4)\n",
    "        ax2.scatter(reduced[0, 0], reduced[0, 1], \n",
    "                   c='green', s=200, marker='o', zorder=5, \n",
    "                   edgecolors='black', linewidth=2, label='Inicio')\n",
    "        ax2.scatter(reduced[-1, 0], reduced[-1, 1], \n",
    "                   c='red', s=200, marker='s', zorder=5, \n",
    "                   edgecolors='black', linewidth=2, label='Final')\n",
    "        ax2.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%})', fontsize=11)\n",
    "        ax2.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%})', fontsize=11)\n",
    "        ax2.set_title(f'Trayectoria en Espacio de Estados: {pattern.capitalize()}',\n",
    "                     fontsize=12, fontweight='bold')\n",
    "        ax2.legend(loc='best')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Visualizaci√≥n completada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß† Interpretaci√≥n de Patrones\n",
    "\n",
    "**Random (Aleatorio):**\n",
    "- Spikes distribuidos uniformemente\n",
    "- Trayectoria err√°tica en espacio de estados\n",
    "- Topolog√≠a: pocas caracter√≠sticas persistentes\n",
    "\n",
    "**Synchronized (Sincronizado):**\n",
    "- Todas las neuronas disparan juntas\n",
    "- Trayectoria lineal (baja dimensionalidad intr√≠nseca)\n",
    "- Topolog√≠a: estructura simple, sin ciclos\n",
    "\n",
    "**Sequential (Secuencial):**\n",
    "- Activaci√≥n en cascada\n",
    "- Trayectoria **c√≠clica** (patr√≥n repetitivo)\n",
    "- Topolog√≠a: **bucles detectables** (H‚ÇÅ > 0)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis topol√≥gico de spike trains\n",
    "print(\"üîç Analizando topolog√≠a de patrones de disparo...\\n\")\n",
    "\n",
    "spike_diagrams = {}\n",
    "\n",
    "for pattern in patterns:\n",
    "    print(f\"‚è≥ Procesando patr√≥n: {pattern}\")\n",
    "    result = ripser(state_spaces[pattern], maxdim=1, thresh=15.0)\n",
    "    spike_diagrams[pattern] = result['dgms']\n",
    "    print(f\"   H‚ÇÄ: {len(result['dgms'][0])} componentes\")\n",
    "    print(f\"   H‚ÇÅ: {len(result['dgms'][1])} ciclos\\n\")\n",
    "\n",
    "# Visualizar diagramas de persistencia\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for idx, pattern in enumerate(patterns):\n",
    "    plot_diagrams(spike_diagrams[pattern], ax=axes[idx])\n",
    "    axes[idx].set_title(f'Persistencia: {pattern.capitalize()}\\n' + \n",
    "                       f'H‚ÇÅ = {len(spike_diagrams[pattern][1])} ciclos',\n",
    "                       fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Hallazgos Clave:\")\n",
    "print(\"   ‚Ä¢ El patr√≥n SECUENCIAL debe mostrar ciclos robustos (H‚ÇÅ alto)\")\n",
    "print(\"   ‚Ä¢ El patr√≥n SINCRONIZADO debe tener estructura simple (H‚ÇÅ bajo)\")\n",
    "print(\"   ‚Ä¢ El patr√≥n ALEATORIO debe tener caracter√≠sticas cerca de la diagonal\")\n",
    "print(\"\\n‚úÖ TDA detecta exitosamente patrones temporales en actividad neuronal!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Caracter√≠sticas Topol√≥gicas para Machine Learning\n",
    "\n",
    "### 7.1 Vectorizaci√≥n de Diagramas\n",
    "\n",
    "Para usar TDA en ML, necesitamos convertir diagramas a vectores de caracter√≠sticas:\n",
    "\n",
    "1. **Amplitud de Persistencia:** $\\max(death - birth)$\n",
    "2. **Entrop√≠a de Persistencia:** $-\\sum p_i \\log(p_i)$ donde $p_i = \\frac{L_i}{\\sum L_j}$\n",
    "3. **N√∫mero de Betti:** Contar caracter√≠sticas en umbrales espec√≠ficos\n",
    "4. **Estad√≠sticas de lifetime:** Media, mediana, desviaci√≥n\n",
    "\n",
    "### 7.2 Aplicaci√≥n: Clasificaci√≥n de Estados\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_topological_features(diagram, dim=1):\n",
    "    \"\"\"\n",
    "    Extrae caracter√≠sticas escalares de un diagrama de persistencia.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    diagram : numpy array\n",
    "        Diagrama de persistencia (n_points x 2)\n",
    "    dim : int\n",
    "        Dimensi√≥n homol√≥gica\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    if len(diagram[dim]) == 0:\n",
    "        return {'n_features': 0, 'max_persistence': 0, \n",
    "                'mean_persistence': 0, 'entropy': 0}\n",
    "    \n",
    "    # Filtrar infinitos\n",
    "    dgm = diagram[dim][np.isfinite(diagram[dim][:, 1])]\n",
    "    \n",
    "    if len(dgm) == 0:\n",
    "        return {'n_features': 0, 'max_persistence': 0, \n",
    "                'mean_persistence': 0, 'entropy': 0}\n",
    "    \n",
    "    # Lifetimes (persistencias)\n",
    "    lifetimes = dgm[:, 1] - dgm[:, 0]\n",
    "    \n",
    "    # Caracter√≠sticas\n",
    "    features['n_features'] = len(dgm)\n",
    "    features['max_persistence'] = np.max(lifetimes)\n",
    "    features['mean_persistence'] = np.mean(lifetimes)\n",
    "    features['std_persistence'] = np.std(lifetimes)\n",
    "    features['total_persistence'] = np.sum(lifetimes)\n",
    "    \n",
    "    # Entrop√≠a de persistencia\n",
    "    if np.sum(lifetimes) > 0:\n",
    "        probs = lifetimes / np.sum(lifetimes)\n",
    "        entropy = -np.sum(probs * np.log(probs + 1e-10))\n",
    "        features['entropy'] = entropy\n",
    "    else:\n",
    "        features['entropy'] = 0\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Extraer caracter√≠sticas de todos los patrones\n",
    "print(\"üìä Extrayendo caracter√≠sticas topol√≥gicas...\\n\")\n",
    "\n",
    "feature_summary = []\n",
    "\n",
    "for pattern in patterns:\n",
    "    feats = extract_topological_features(spike_diagrams[pattern], dim=1)\n",
    "    feats['pattern'] = pattern\n",
    "    feature_summary.append(feats)\n",
    "\n",
    "# Crear DataFrame\n",
    "df_features = pd.DataFrame(feature_summary)\n",
    "df_features = df_features[['pattern', 'n_features', 'max_persistence', \n",
    "                           'mean_persistence', 'entropy']]\n",
    "\n",
    "print(\"Caracter√≠sticas Topol√≥gicas (H‚ÇÅ - Ciclos):\\n\")\n",
    "print(df_features.to_string(index=False))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Visualizar caracter√≠sticas\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "features_to_plot = ['n_features', 'max_persistence', 'mean_persistence', 'entropy']\n",
    "titles = ['N√∫mero de Ciclos', 'M√°xima Persistencia', \n",
    "          'Persistencia Promedio', 'Entrop√≠a de Persistencia']\n",
    "colors = ['#e74c3c', '#3498db', '#2ecc71']\n",
    "\n",
    "for idx, (feat, title) in enumerate(zip(features_to_plot, titles)):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    values = [df_features[df_features['pattern'] == p][feat].values[0] for p in patterns]\n",
    "    bars = ax.bar(patterns, values, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "    ax.set_ylabel(title, fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Patr√≥n', fontsize=11)\n",
    "    ax.set_title(f'{title} por Patr√≥n de Activaci√≥n', fontsize=12, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Agregar valores en las barras\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.2f}',\n",
    "                ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Extracci√≥n de caracter√≠sticas completada\")\n",
    "print(\"\\nüí° Observa c√≥mo cada patr√≥n tiene una 'firma topol√≥gica' √∫nica!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Firmas Topol√≥gicas\n",
    "\n",
    "Cada tipo de actividad neuronal tiene caracter√≠sticas topol√≥gicas distintivas:\n",
    "\n",
    "| Patr√≥n | N¬∞ Ciclos | Max Persist | Entrop√≠a | Interpretaci√≥n |\n",
    "|--------|-----------|-------------|----------|----------------|\n",
    "| **Random** | Bajo | Bajo | Baja | Sin estructura | \n",
    "| **Synchronized** | Muy bajo | Bajo | Muy baja | Colapso dimensional |\n",
    "| **Sequential** | Alto | Alto | Alta | Estructura c√≠clica robusta |\n",
    "\n",
    "**Aplicaci√≥n pr√°ctica:** Estas caracter√≠sticas pueden usarse para:\n",
    "- Clasificar estados cerebrales\n",
    "- Detectar patrones anormales\n",
    "- Predecir transiciones de estado\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Optimizaci√≥n para Grandes Datasets\n",
    "\n",
    "### 8.1 Desaf√≠os Computacionales\n",
    "\n",
    "En neurociencias reales:\n",
    "- **Miles de neuronas:** N = 1000-10000\n",
    "- **Alta dimensionalidad:** Espacios de 100+ dimensiones\n",
    "- **Datos temporales:** Miles de time bins\n",
    "\n",
    "### 8.2 Estrategias de Optimizaci√≥n\n",
    "\n",
    "1. **Subsampling:** Reducir n√∫mero de puntos\n",
    "2. **Landmark selection:** Elegir puntos representativos\n",
    "3. **Threshold early:** Limitar radio m√°ximo\n",
    "4. **Dimensi√≥n reducida:** PCA/UMAP antes de TDA\n",
    "5. **Sparse distance matrix:** Solo distancias < threshold\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_tda_methods(n_points_list, n_dimensions=10):\n",
    "    \"\"\"\n",
    "    Compara tiempos de c√≥mputo para diferentes tama√±os de datos.\n",
    "    \"\"\"\n",
    "    import time\n",
    "    \n",
    "    results = {'n_points': [], 'time': [], 'method': []}\n",
    "    \n",
    "    for n_points in n_points_list:\n",
    "        print(f\"\\nüìä Benchmarking con {n_points} puntos...\")\n",
    "        data = np.random.randn(n_points, n_dimensions)\n",
    "        \n",
    "        # M√©todo 1: Ripser est√°ndar\n",
    "        start = time.time()\n",
    "        result = ripser(data, maxdim=1, thresh=2.0)\n",
    "        elapsed = time.time() - start\n",
    "        results['n_points'].append(n_points)\n",
    "        results['time'].append(elapsed)\n",
    "        results['method'].append('Ripser (full)')\n",
    "        print(f\"   Ripser (full): {elapsed:.3f}s\")\n",
    "        \n",
    "        # M√©todo 2: Con reducci√≥n dimensional (PCA)\n",
    "        start = time.time()\n",
    "        pca = PCA(n_components=min(5, n_dimensions))\n",
    "        data_reduced = pca.fit_transform(data)\n",
    "        result = ripser(data_reduced, maxdim=1, thresh=2.0)\n",
    "        elapsed = time.time() - start\n",
    "        results['n_points'].append(n_points)\n",
    "        results['time'].append(elapsed)\n",
    "        results['method'].append('PCA + Ripser')\n",
    "        print(f\"   PCA + Ripser: {elapsed:.3f}s\")\n",
    "        \n",
    "        # M√©todo 3: Subsampling\n",
    "        if n_points > 100:\n",
    "            start = time.time()\n",
    "            indices = np.random.choice(n_points, size=min(100, n_points), replace=False)\n",
    "            data_sub = data[indices]\n",
    "            result = ripser(data_sub, maxdim=1, thresh=2.0)\n",
    "            elapsed = time.time() - start\n",
    "            results['n_points'].append(n_points)\n",
    "            results['time'].append(elapsed)\n",
    "            results['method'].append('Subsampling (100)')\n",
    "            print(f\"   Subsampling: {elapsed:.3f}s\")\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Ejecutar benchmark\n",
    "print(\"‚è±Ô∏è Ejecutando benchmark de m√©todos TDA...\")\n",
    "n_points_to_test = [50, 100, 200, 500]\n",
    "benchmark_df = benchmark_tda_methods(n_points_to_test, n_dimensions=10)\n",
    "\n",
    "# Visualizar resultados\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "for method in benchmark_df['method'].unique():\n",
    "    data = benchmark_df[benchmark_df['method'] == method]\n",
    "    ax.plot(data['n_points'], data['time'], 'o-', \n",
    "            linewidth=2, markersize=8, label=method)\n",
    "\n",
    "ax.set_xlabel('N√∫mero de Puntos', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Tiempo de C√≥mputo (s)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Comparaci√≥n de Eficiencia: M√©todos TDA', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_yscale('log')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Benchmark completado\")\n",
    "print(\"\\nüí° Recomendaciones:\")\n",
    "print(\"   ‚Ä¢ Para N < 200: Usa Ripser directamente\")\n",
    "print(\"   ‚Ä¢ Para N > 200: Considera PCA o subsampling\")\n",
    "print(\"   ‚Ä¢ Para dimensi√≥n alta: PCA a 5-10 dimensiones\")\n",
    "print(\"   ‚Ä¢ Siempre usa threshold adecuado para tu escala de datos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Ejercicios Avanzados\n",
    "\n",
    "### Ejercicio 1: An√°lisis de tus propios spike trains\n",
    "\n",
    "Genera spike trains con par√°metros personalizados y analiza su topolog√≠a:\n",
    "\n",
    "```python\n",
    "# Crea un patr√≥n intermitente (alterna entre sincronizado y aleatorio)\n",
    "# Analiza c√≥mo cambia la topolog√≠a en el tiempo\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Espacio para Ejercicio 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2: Clasificador topol√≥gico\n",
    "\n",
    "Usa caracter√≠sticas topol√≥gicas para entrenar un clasificador:\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 1. Genera m√∫ltiples ejemplos de cada patr√≥n\n",
    "# 2. Extrae caracter√≠sticas topol√≥gicas\n",
    "# 3. Entrena un clasificador\n",
    "# 4. Eval√∫a precisi√≥n\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Espacio para Ejercicio 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3: An√°lisis temporal\n",
    "\n",
    "Estudia c√≥mo evoluciona la topolog√≠a durante una transici√≥n de estados:\n",
    "\n",
    "```python\n",
    "# Genera datos que transicionan de 'synchronized' a 'random'\n",
    "# Calcula topolog√≠a en ventanas deslizantes\n",
    "# Visualiza la evoluci√≥n de n√∫meros de Betti\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Espacio para Ejercicio 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Resumen y Conclusiones\n",
    "\n",
    "### ‚úÖ Lo que dominamos:\n",
    "\n",
    "1. **Filtraciones:** Diferentes m√©todos (Rips, Alpha, ƒåech) y cu√°ndo usar cada uno\n",
    "2. **Distancias:** Bottleneck y Wasserstein para comparar diagramas\n",
    "3. **Spike trains:** Conversi√≥n a espacio de estados y an√°lisis topol√≥gico\n",
    "4. **Caracter√≠sticas:** Vectorizaci√≥n para machine learning\n",
    "5. **Optimizaci√≥n:** Estrategias para datos masivos\n",
    "\n",
    "### üîë Mensajes Clave:\n",
    "\n",
    "- **TDA captura patrones temporales** en actividad neuronal\n",
    "- **Ciclos (H‚ÇÅ)** revelan retroalimentaci√≥n y patrones repetitivos\n",
    "- **Firmas topol√≥gicas** son distintivas para cada tipo de actividad\n",
    "- **Distancias entre diagramas** cuantifican similitud entre estados\n",
    "- **Optimizaci√≥n es crucial** para aplicaciones reales\n",
    "\n",
    "### üß† Impacto en Neurociencias:\n",
    "\n",
    "TDA proporciona:\n",
    "- **Descripci√≥n invariante** de patrones neuronales\n",
    "- **Detecci√≥n robusta** de estructuras funcionales\n",
    "- **Comparaci√≥n cuantitativa** entre condiciones\n",
    "- **Base para biomarcadores** topol√≥gicos\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Pr√≥ximo Tutorial\n",
    "\n",
    "En el **Tutorial 3: Conectividad Cerebral**, exploraremos:\n",
    "\n",
    "- An√°lisis de conectomas (matrices de conectividad)\n",
    "- TDA aplicado a redes funcionales vs estructurales\n",
    "- Detecci√≥n de comunidades topol√≥gicas\n",
    "- An√°lisis de grafos cerebrales ponderados\n",
    "- Estudios de caso con datos fMRI reales\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Referencias\n",
    "\n",
    "### Papers Clave:\n",
    "1. Giusti et al. (2015). \"Clique topology reveals intrinsic structure in neural correlations\". *PNAS*\n",
    "2. Petri et al. (2014). \"Homological scaffolds of brain functional networks\". *Journal of the Royal Society Interface*\n",
    "3. Curto (2017). \"What can topology tell us about the neural code?\". *Bulletin of the AMS*\n",
    "4. Sizemore et al. (2019). \"Cliques and cavities in the human connectome\". *Journal of Computational Neuroscience*\n",
    "\n",
    "### Software:\n",
    "- [Ripser](https://ripser.scikit-tda.org/)\n",
    "- [GUDHI](https://gudhi.inria.fr/)\n",
    "- [Giotto-TDA](https://giotto-ai.github.io/gtda-docs/)\n",
    "- [Persim](https://persim.scikit-tda.org/)\n",
    "\n",
    "---\n",
    "\n",
    "**Autor:** MARK-126  \n",
    "**√öltima actualizaci√≥n:** 2025-01-13  \n",
    "**Licencia:** MIT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
